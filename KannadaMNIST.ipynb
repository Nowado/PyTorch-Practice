{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('Dig-MNIST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df_train.drop('label',axis=1)\n",
    "train_targets=df_train['label']\n",
    "\n",
    "X_test=df_test.drop('label',axis=1)\n",
    "Y_test=df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train_data,\n",
    "                                                  train_targets,\n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "Y_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "Y_val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGSIZE = 28\n",
    "\n",
    "class KannadaDataSet(Dataset):\n",
    "    def __init__(self, images, labels, transforms = None):\n",
    "        self.X = images\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = self.X.iloc[i,:]\n",
    "        data = np.array(data).astype(np.uint8).reshape(IMGSIZE,IMGSIZE,1)\n",
    "        \n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "\n",
    "        if self.y is not None:\n",
    "            return (data, self.y[i])\n",
    "        else:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose(([transforms.ToPILImage(),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "val_trans = transforms.Compose(([transforms.ToPILImage(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,), (0.5,))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data = KannadaDataSet(X_train, Y_train, train_trans)\n",
    "val_data = KannadaDataSet(X_val, Y_val, val_trans)\n",
    "test_data = KannadaDataSet(X_test, Y_test, val_trans)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv1_bn): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_1): Conv2d(4, 8, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_1_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (out): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(num_features=4)\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=4, stride=1, padding=1)\n",
    "        self.conv1_1_bn = nn.BatchNorm2d(num_features=8)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(num_features=16)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3_bn = nn.BatchNorm2d(num_features=32)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(32*2*2, 64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32) \n",
    "        self.fc3 = nn.Linear(in_features=32, out_features=16) \n",
    "        self.out = nn.Linear(in_features=16, out_features=10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_1_bn(x)\n",
    "        x = F.relu(x)       \n",
    "        \n",
    "        x = self.pool1(x) \n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x) \n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x) \n",
    "        \n",
    "        x = x.view(-1, 32*2*2)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=.5*1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] train loss: 0.001560 acc: 93.404 - valid loss: 0.000469 acc: 98.075\n",
      "Epoch [2/10] train loss: 0.000346 acc: 98.654 - valid loss: 0.001325 acc: 94.442\n",
      "Epoch [3/10] train loss: 0.000282 acc: 98.929 - valid loss: 0.000227 acc: 99.175\n",
      "Epoch [4/10] train loss: 0.000219 acc: 99.148 - valid loss: 0.000191 acc: 99.308\n",
      "Epoch [5/10] train loss: 0.000177 acc: 99.321 - valid loss: 0.000212 acc: 99.217\n",
      "Epoch [6/10] train loss: 0.000173 acc: 99.296 - valid loss: 0.000334 acc: 98.700\n",
      "Epoch [7/10] train loss: 0.000152 acc: 99.371 - valid loss: 0.000239 acc: 99.100\n",
      "Epoch [8/10] train loss: 0.000139 acc: 99.456 - valid loss: 0.000200 acc: 99.408\n",
      "Epoch [9/10] train loss: 0.000115 acc: 99.544 - valid loss: 0.000177 acc: 99.417\n",
      "Epoch [10/10] train loss: 0.000121 acc: 99.575 - valid loss: 0.000213 acc: 99.283\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "nn_output=[]\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    net.train()\n",
    "    #i=0\n",
    "    for data in train_loader:\n",
    "        \"\"\"i+=1\n",
    "        if i%100==0:\n",
    "            print(i)\"\"\"\n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "        \n",
    "        net.zero_grad()  \n",
    "        output = net(X)\n",
    "        tloss = criterion(output, y) \n",
    "        tloss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        epoch_loss += tloss.item()\n",
    "        epoch_correct += get_num_correct(output, y)\n",
    "        \n",
    "    net.eval() \n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            \n",
    "            preds = net(X)\n",
    "            vloss = criterion(preds, y)\n",
    "            \n",
    "            val_correct += get_num_correct(preds, y)\n",
    "            val_loss += vloss.item()\n",
    "            \n",
    "    tmp_nn_output = [epoch + 1,EPOCHS,\n",
    "                     epoch_loss/len(train_loader.dataset),epoch_correct/len(train_loader.dataset)*100,\n",
    "                     val_loss/len(val_loader.dataset), val_correct/len(val_loader.dataset)*100,\n",
    "                     test_loss/len(test_loader.dataset), test_correct/len(test_loader.dataset)*100\n",
    "                    ]\n",
    "    nn_output.append(tmp_nn_output)\n",
    "    \n",
    "    print('Epoch [{}/{}] train loss: {:.6f} acc: {:.3f} - valid loss: {:.6f} acc: {:.3f}'\n",
    "        .format(*tmp_nn_output))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=0)\n",
    "self.conv1_bn = nn.BatchNorm2d(num_features=4)\n",
    "\n",
    "self.conv1_1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=0)\n",
    "self.conv1_1_bn = nn.BatchNorm2d(num_features=8)\n",
    "self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=0)\n",
    "self.conv2_bn = nn.BatchNorm2d(num_features=16)\n",
    "self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "self.conv3_bn = nn.BatchNorm2d(num_features=32)\n",
    "self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.fc1 = nn.Linear(32*2*2, 64)\n",
    "self.fc2 = nn.Linear(in_features=64, out_features=32) \n",
    "self.fc3 = nn.Linear(in_features=32, out_features=16) \n",
    "self.out = nn.Linear(in_features=16, out_features=10) \n",
    "        \n",
    "Epoch [1/10] train loss: 0.007964 acc: 62.569 - valid loss: 0.007653 acc: 69.433 - Test loss: 0.000000 acc: 0.000\n",
    "Epoch [2/10] train loss: 0.005877 acc: 74.542 - valid loss: 0.006809 acc: 68.792 - Test loss: 0.000000 acc: 0.000\n",
    "Epoch [3/10] train loss: 0.005233 acc: 72.723 - valid loss: 0.006182 acc: 71.967 - Test loss: 0.000000 acc: 0.000\n",
    "(...)\n",
    "Epoch [9/10] train loss: 0.004652 acc: 79.631 - valid loss: 0.004377 acc: 79.767 - Test loss: 0.000000 acc: 0.000\n",
    "Epoch [10/10] train loss: 0.005154 acc: 77.204 - valid loss: 0.003557 acc: 83.100 - Test loss: 0.000000 acc: 0.000\n",
    "\n",
    "Possibly could jumpp further with enough training, but lets try slightly bigger net\n",
    "\n",
    "_____________________________________________\n",
    "\n",
    "self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "self.conv1_bn = nn.BatchNorm2d(num_features=4)\n",
    "\n",
    "self.conv1_1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=4, stride=1, padding=1)\n",
    "self.conv1_1_bn = nn.BatchNorm2d(num_features=8)\n",
    "self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "self.conv2_bn = nn.BatchNorm2d(num_features=16)\n",
    "self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "self.conv3_bn = nn.BatchNorm2d(num_features=32)\n",
    "self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.fc1 = nn.Linear(32*2*2, 64)\n",
    "self.fc2 = nn.Linear(in_features=64, out_features=32) \n",
    "self.fc3 = nn.Linear(in_features=32, out_features=16) \n",
    "self.out = nn.Linear(in_features=16, out_features=10) \n",
    "\n",
    "Epoch [1/10] train loss: 0.006367 acc: 68.615 - valid loss: 0.018534 acc: 67.858\n",
    "Epoch [2/10] train loss: 0.003977 acc: 85.329 - valid loss: 0.004139 acc: 85.192\n",
    "Epoch [3/10] train loss: 0.002776 acc: 91.090 - valid loss: 0.002362 acc: 92.925\n",
    "Epoch [4/10] train loss: 0.002922 acc: 91.348 - valid loss: 0.002204 acc: 93.967\n",
    "Epoch [5/10] train loss: 0.002061 acc: 93.890 - valid loss: 0.007511 acc: 75.125\n",
    "Epoch [6/10] train loss: 0.004253 acc: 86.092 - valid loss: 0.008214 acc: 80.292\n",
    "Epoch [7/10] train loss: 0.004008 acc: 85.940 - valid loss: 0.002770 acc: 85.733\n",
    "Epoch [8/10] train loss: 0.002749 acc: 85.617 - valid loss: 0.003397 acc: 83.792\n",
    "Epoch [9/10] train loss: 0.006693 acc: 66.821 - valid loss: 0.005743 acc: 69.350\n",
    "Epoch [10/10] train loss: 0.004832 acc: 76.000 - valid loss: 0.004011 acc: 84.067\n",
    "\n",
    "\n",
    "Looking at stability, it could probably use lower lr. Or more epochs. Either one would however take a lot of time, so that's a no. Or dropout, but I really don't like dropout, so that's also a no. Or early stopping, but I'm not huge fan of the one either.\n",
    "Lets tweak whole thing a bit.\n",
    "_______________\n",
    "\n",
    "self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1, padding=2)\n",
    "self.conv1_bn = nn.BatchNorm2d(num_features=4)\n",
    "\n",
    "self.conv1_1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=2, stride=1, padding=1)\n",
    "self.conv1_1_bn = nn.BatchNorm2d(num_features=8)\n",
    "self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2, stride=1, padding=1)\n",
    "self.conv2_bn = nn.BatchNorm2d(num_features=16)\n",
    "self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv2_1 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=2, stride=1, padding=1)\n",
    "self.conv2_1_bn = nn.BatchNorm2d(num_features=16)\n",
    "self.pool2_1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=2, stride=1, padding=0)\n",
    "self.conv3_bn = nn.BatchNorm2d(num_features=32)\n",
    "self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "self.fc1 = nn.Linear(32, 64)\n",
    "self.fc2 = nn.Linear(in_features=64, out_features=32) \n",
    "self.fc3 = nn.Linear(in_features=32, out_features=16) \n",
    "self.out = nn.Linear(in_features=16, out_features=10) \n",
    "\n",
    "Epoch [1/10] train loss: 0.009979 acc: 45.519 - valid loss: 0.008471 acc: 52.408\n",
    "Epoch [2/10] train loss: 0.008404 acc: 56.490 - valid loss: 0.013844 acc: 37.758\n",
    "Epoch [3/10] train loss: 0.006901 acc: 63.650 - valid loss: 0.007029 acc: 69.950\n",
    "Epoch [4/10] train loss: 0.006987 acc: 64.842 - valid loss: 0.006976 acc: 63.975\n",
    "Epoch [5/10] train loss: 0.006887 acc: 64.690 - valid loss: 0.008358 acc: 56.225\n",
    "Epoch [6/10] train loss: 0.006616 acc: 66.040 - valid loss: 0.007518 acc: 60.033\n",
    "Epoch [7/10] train loss: 0.006498 acc: 67.485 - valid loss: 0.006138 acc: 69.233\n",
    "Epoch [8/10] train loss: 0.005721 acc: 72.546 - valid loss: 0.005793 acc: 68.983\n",
    "Epoch [9/10] train loss: 0.005467 acc: 74.433 - valid loss: 0.005929 acc: 75.350\n",
    "Epoch [10/10] train loss: 0.005060 acc: 77.998 - valid loss: 0.007166 acc: 70.967\n",
    "\n",
    "Looks more stable, but still no great. It's honestly pretty much betting at this point, but lets try second setting with slightly lower lr.\n",
    "\n",
    "____\n",
    "Epoch [1/30] train loss: 0.001838 acc: 92.292 - valid loss: 0.000555 acc: 97.825\n",
    "Epoch [2/30] train loss: 0.000361 acc: 98.604 - valid loss: 0.000330 acc: 98.817\n",
    "Epoch [3/30] train loss: 0.000265 acc: 98.906 - valid loss: 0.000260 acc: 99.083\n",
    "Epoch [4/30] train loss: 0.000212 acc: 99.188 - valid loss: 0.000176 acc: 99.333\n",
    "Epoch [5/30] train loss: 0.000208 acc: 99.221 - valid loss: 0.000360 acc: 98.692\n",
    "Epoch [6/30] train loss: 0.000156 acc: 99.385 - valid loss: 0.000196 acc: 99.358\n",
    "Epoch [7/30] train loss: 0.000142 acc: 99.454 - valid loss: 0.000221 acc: 99.242\n",
    "Epoch [8/30] train loss: 0.000134 acc: 99.487 - valid loss: 0.000189 acc: 99.392\n",
    "Epoch [9/30] train loss: 0.000129 acc: 99.494 - valid loss: 0.000218 acc: 99.350\n",
    "Epoch [10/30] train loss: 0.000105 acc: 99.592 - valid loss: 0.000214 acc: 99.358\n",
    "Epoch [11/30] train loss: 0.000107 acc: 99.596 - valid loss: 0.000174 acc: 99.433\n",
    "Epoch [12/30] train loss: 0.000125 acc: 99.525 - valid loss: 0.000213 acc: 99.342\n",
    "Epoch [13/30] train loss: 0.000117 acc: 99.558 - valid loss: 0.000174 acc: 99.450\n",
    "Epoch [14/30] train loss: 0.000094 acc: 99.638 - valid loss: 0.000177 acc: 99.425\n",
    "Epoch [15/30] train loss: 0.000108 acc: 99.598 - valid loss: 0.000145 acc: 99.517\n",
    "\n",
    "Ok, apparently slashing lr in half is magic. It honestly looks borderline too good, but there's no obvious issue...\n",
    "\n",
    "And accuracy on test set is not terrible. Huh. Could be probably tweaked further and double checked, but this will do for general purpose PyTorch practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.3877487629652\n"
     ]
    }
   ],
   "source": [
    "  with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            X = data[0]\n",
    "            y = data[1]\n",
    "            \n",
    "            preds = net(X) \n",
    "            tstloss = criterion(preds, y) \n",
    "            \n",
    "            test_correct += get_num_correct(preds, y)\n",
    "            test_loss += tstloss.item()\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
